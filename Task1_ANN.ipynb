{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the package needed\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : 54058, Val Data: 18020, Test Data: 18020\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/datasets/raw.csv')\n",
    "\n",
    "# clean_train_data, clean_test_data = train_test_split(data_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_data.shape[0], val_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the \"Category\" and \"Style\" columns in the train_data, val_data, and test_data dataframes\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder on the \"Category\" column in the train_data dataframe\n",
    "label_encoder.fit(train_data['Category'])\n",
    "\n",
    "# Encode the \"Category\" column in the train_data dataframe\n",
    "train_data['Category'] = label_encoder.transform(train_data['Category'])\n",
    "\n",
    "# Encode the \"Category\" column in the val_data dataframe\n",
    "val_data['Category'] = label_encoder.transform(val_data['Category'])\n",
    "\n",
    "# Encode the \"Category\" column in the test_data dataframe\n",
    "test_data['Category'] = label_encoder.transform(test_data['Category'])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the label encoder on the \"Style\" column in the train_data dataframe\n",
    "label_encoder.fit(train_data['Style'])\n",
    "\n",
    "# Encode the \"Style\" column in the train_data dataframe\n",
    "train_data['Style'] = label_encoder.transform(train_data['Style'])\n",
    "\n",
    "# Encode the \"Style\" column in the val_data dataframe\n",
    "val_data['Style'] = label_encoder.transform(val_data['Style'])\n",
    "\n",
    "# Encode the \"Style\" column in the test_data dataframe\n",
    "test_data['Style'] = label_encoder.transform(test_data['Style'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = train_data.drop(\"Path\", axis=1)\n",
    "# test_data = test_data.drop(\"Path\", axis=1)\n",
    "#  val_data = val_data.drop(\"Path\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Category'] = train_data['Category'].astype('str')\n",
    "val_data['Category'] = val_data['Category'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Style</th>\n",
       "      <th>Category_Path</th>\n",
       "      <th>Full_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74633</th>\n",
       "      <td>1583contemporary-side-tables-and-end-tables.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>./data/datasets/raw/tables/Contemporary</td>\n",
       "      <td>./data/datasets/raw/tables/Contemporary/1583co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62545</th>\n",
       "      <td>19476transitional-table-lamps.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>./data/datasets/raw/lamps/Transitional</td>\n",
       "      <td>./data/datasets/raw/lamps/Transitional/19476tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83052</th>\n",
       "      <td>44235midcentury-side-tables-and-end-tables.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>./data/datasets/raw/tables/Midcentury</td>\n",
       "      <td>./data/datasets/raw/tables/Midcentury/44235mid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61685</th>\n",
       "      <td>8174traditional-table-lamps.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>./data/datasets/raw/lamps/Traditional</td>\n",
       "      <td>./data/datasets/raw/lamps/Traditional/8174trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47877</th>\n",
       "      <td>27647craftsman-table-lamps.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>./data/datasets/raw/lamps/Craftsman</td>\n",
       "      <td>./data/datasets/raw/lamps/Craftsman/27647craft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>5143southwestern-armchairs-and-accent-chairs.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>./data/datasets/raw/chairs/Southwestern</td>\n",
       "      <td>./data/datasets/raw/chairs/Southwestern/5143so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>6058traditional-panel-beds.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>./data/datasets/raw/beds/Traditional</td>\n",
       "      <td>./data/datasets/raw/beds/Traditional/6058tradi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44069</th>\n",
       "      <td>3430contemporary-floor-lamps.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>./data/datasets/raw/lamps/Contemporary</td>\n",
       "      <td>./data/datasets/raw/lamps/Contemporary/3430con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18177</th>\n",
       "      <td>6940modern-dining-chairs.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>./data/datasets/raw/chairs/Modern</td>\n",
       "      <td>./data/datasets/raw/chairs/Modern/6940modern-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26415</th>\n",
       "      <td>24787transitional-armchairs-and-accent-chairs.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>./data/datasets/raw/chairs/Transitional</td>\n",
       "      <td>./data/datasets/raw/chairs/Transitional/24787t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54058 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Image_Name Category  Style  \\\n",
       "74633    1583contemporary-side-tables-and-end-tables.jpg        6      2   \n",
       "62545                  19476transitional-table-lamps.jpg        4     15   \n",
       "83052     44235midcentury-side-tables-and-end-tables.jpg        6      9   \n",
       "61685                    8174traditional-table-lamps.jpg        4     14   \n",
       "47877                     27647craftsman-table-lamps.jpg        4      3   \n",
       "...                                                  ...      ...    ...   \n",
       "19500   5143southwestern-armchairs-and-accent-chairs.jpg        2     13   \n",
       "3601                      6058traditional-panel-beds.jpg        1     14   \n",
       "44069                   3430contemporary-floor-lamps.jpg        4      2   \n",
       "18177                       6940modern-dining-chairs.jpg        2     10   \n",
       "26415  24787transitional-armchairs-and-accent-chairs.jpg        2     15   \n",
       "\n",
       "                                 Category_Path  \\\n",
       "74633  ./data/datasets/raw/tables/Contemporary   \n",
       "62545   ./data/datasets/raw/lamps/Transitional   \n",
       "83052    ./data/datasets/raw/tables/Midcentury   \n",
       "61685    ./data/datasets/raw/lamps/Traditional   \n",
       "47877      ./data/datasets/raw/lamps/Craftsman   \n",
       "...                                        ...   \n",
       "19500  ./data/datasets/raw/chairs/Southwestern   \n",
       "3601      ./data/datasets/raw/beds/Traditional   \n",
       "44069   ./data/datasets/raw/lamps/Contemporary   \n",
       "18177        ./data/datasets/raw/chairs/Modern   \n",
       "26415  ./data/datasets/raw/chairs/Transitional   \n",
       "\n",
       "                                               Full_Path  \n",
       "74633  ./data/datasets/raw/tables/Contemporary/1583co...  \n",
       "62545  ./data/datasets/raw/lamps/Transitional/19476tr...  \n",
       "83052  ./data/datasets/raw/tables/Midcentury/44235mid...  \n",
       "61685  ./data/datasets/raw/lamps/Traditional/8174trad...  \n",
       "47877  ./data/datasets/raw/lamps/Craftsman/27647craft...  \n",
       "...                                                  ...  \n",
       "19500  ./data/datasets/raw/chairs/Southwestern/5143so...  \n",
       "3601   ./data/datasets/raw/beds/Traditional/6058tradi...  \n",
       "44069  ./data/datasets/raw/lamps/Contemporary/3430con...  \n",
       "18177  ./data/datasets/raw/chairs/Modern/6940modern-d...  \n",
       "26415  ./data/datasets/raw/chairs/Transitional/24787t...  \n",
       "\n",
       "[54058 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54047 validated image filenames belonging to 6 classes.\n",
      "Found 18019 validated image filenames belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_data,\n",
    "        directory='./',\n",
    "        x_col=\"Full_Path\",\n",
    "        y_col=\"Category\",\n",
    "        target_size=(350, 350),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_dataframe(\n",
    "        dataframe=val_data,\n",
    "        directory='./',\n",
    "        x_col=\"Full_Path\",\n",
    "        y_col=\"Category\",\n",
    "        target_size=(350, 350),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(train_loss, val_loss, train_metric, val_metric, metric_name='Accuracy'):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(train_loss, 'r--')\n",
    "    plt.plot(val_loss, 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(train_metric, 'r--')\n",
    "    plt.plot(val_metric, 'b--')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = (350,350,3)\n",
    "HIDDEN_LAYER_DIM = 256\n",
    "OUTPUT_CLASSES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=INPUT_DIM),\n",
    "    Dense(HIDDEN_LAYER_DIM, activation='relu'),\n",
    "    Dense(OUTPUT_CLASSES, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">367500</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">94,080,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m367500\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m94,080,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,082,312</span> (358.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m94,082,312\u001b[0m (358.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,082,312</span> (358.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m94,082,312\u001b[0m (358.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 6), output.shape=(None, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_generator, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mvalidation_generator, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:554\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n\u001b[1;32m--> 554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    557\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    558\u001b[0m         )\n\u001b[0;32m    560\u001b[0m output, from_logits \u001b[38;5;241m=\u001b[39m _get_logits(\n\u001b[0;32m    561\u001b[0m     output, from_logits, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m )\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 6), output.shape=(None, 8)"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=50, validation_data=validation_generator, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
